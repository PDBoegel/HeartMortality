---
title: "Heart Disease Mortality Data Among US Adults (35+) by State/Territory and County"
author: "Ben Malewicki, Dalton Marske, Paul Boegel, Taner Carlson"
date: "21 December 2017"
output:
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
  pdf_document:
    toc: yes
    toc_depth: '4'
---
#Abstract

<div style="text-indent: 30px;">This report looked to bring into light and examine how United States County-based Socioeconomic
Factors impact Heart Disease. Appropriate data from the U.S. Census was fit into linear models, which
were developed using R, a scripting language. The linear models revealed that age and diabetes have
significant correlations to Heart Disease mortality. 

#Introduction

<div style="text-indent: 30px;">In the United States, an average of 630,000 people per year die from Heart Disease- accounting for
1 in every 4 deaths of American citizens. An American citizen has a heart attack every 40 seconds.
Over 200 billion dollars are lost every year to Heart Disease. The goal of this project is to further
analyze and pinpoint how socioeconomic factors of where one lives impacts this Heart Disease
epidemic. With explanatory variables like population count, obesity rates, diagnosed diabetes,
average wage, and many other factors listed later, this report will evaluate and quantify the
individual impact (relative to the other explanatory variables) each explanatory variable has on
Heart Disease in the United States. First, the objective data will be introduced (from where it was
gathered, its level of reliability, etc.), and filed into understandable plots and equations. After
creating these linear models and regressing the data into observable and objective representations
(graphs, linear equations, etc.), this report aims to transparently and rationally explain any
findings and discovered relationships. Each analysis will weigh pros and cons of individual linear
models and create a reasonable justification awarding the model of highest merit (in relation to this
study). Lastly, this report will comment on the limits of the study, propose and address possible
sources of error, and offer alterations for future studies.

<div style="text-indent: 30px;">The problem of Heart Disease is extremely prevalent, it being the leading cause of both male and
female deaths in the United States. In the past, studies have been done regarding specific
demographics, such as race. Abraham Kagel, for example, produced his study entitled Epidemiologic
studies on of coronary heart disease and stroke in Japanese men living in Japan, Hawaii and
California: Demographic, physical, dietary and biochemical characteristics. His work, contrary to
this report, narrows its focus on a specific limited demographic (Japanese men) living in a specific
area (Pacific land masses). Another study by Pierre-LucBernier covered a broader land demographic -
the globe. His study, The Challenge of Congenital Heart Disease Worldwide: Epidemiologic and
Demographic Facts, emphasized Heart Disease in newborns around the world. This report, unlike the two
aforementioned studies, aims to contribute to the available information by reviewing the connection
between Heart Disease and socioeconomic factors by county within the United States in 2013.

#Data

<div style="text-indent: 30px;">The data in this analysis comes from reliable sources within the U.S. government. Reports from the
Center for Disease Control and Prevention (CDC) acquired obesity and diabetes rates per county in
2013; reports from the Bureau of Labor Statistics acquired average wages per county in 2013; reports
from the United States Census Bureau acquired population data in 2010. These sources provided
cross-sectional data of socioeconomic variables within the United States.  The multiple data sheets
were combined by using Microsoft Excel functions and by matching each county’s FIPS code to
consolidate all the variables of interest into one csv file.

<div style="text-indent: 30px;">While the initial sample size was for n = 3200 counties, after merging all of the necessary
explanatory variables, the final consolidated csv datasheet had observations for an individual’s
probability of experiencing Heart Disease mortality for n = 3130 counties.  This slight reduction is
insignificant to the overall analysis performed because of the large amount of available data.

<div style="text-indent: 30px;">It is noteworthy that the year of one of the data sheets is different. This distinction is trivial
because there are negligible changes from year to year in census data. This report acknowledges the
year discrepancies and continues with the analysis under the assumption that there has been no
significant population shifts between 2010 and 2013. Since United States census data is gathered
every 10 years, this data is the most updated information regarding the population of the United
States.

<div style="text-indent: 30px;">The main outcome of interest is an individual’s chance of dying from Heart Disease based on certain
county-wide socioeconomic factors.  The initial variables used to describe the outcome of interest
included county-wide race population demographics, education levels, obesity and diabetic rates,
unemployment rates, average income per person, population and housing unit density per square mile,
age groups, and gender percentages.  More specific information regarding each variable utilized can
be found in the Appendix B1.  Explanatory variables were chosen by gathering information on the most
common causes of Heart Disease, and then adding several popular demographic differentiations to
filter out general correlations. Each explanatory variable is by county, giving a better
understanding of how general socioeconomic factors affect heart disease mortality chances.

<div style="text-indent: 30px;">Appendix B provides summary statistics for each variable.  After observing the maximum and minimum
amounts relative to a variable’s mean and median, it was apparent that many showed signs of heavily
skewed tails.  POPDENSITY, for example, had an average of 259 people per square mile, with a standard
deviation of 1720.624.  The maximum value for this variable was 69,468, more than forty standard
deviations from the mean.

<div style="text-indent: 30px;">To try to compensate for this reality, two solutions were attempted in the analysis. The first
solution was to logarithmically transform heavily skewed variables to match a decidedly more normal
(Gaussian) distribution, making the data more workable and easy to analyze.  The second solution was
to change each percentage variable into a raw population total.  The motivation behind this was that
percentages can be relatively high even if the county population is extremely small.

<div style="text-indent: 30px;">Histograms of PCTAFRAM and Histogram of LNTOTAFRAM display the percentage of African Americans in each county compared to the
overall transformed raw population number of African Americans per county.  This transformation from
percentages to numbers skewed the data further to the right, the opposite of expectation. Further
analysis on the effects of individual outliers and high leverage points had to be conducted before
disregarding the significance of raw numerical totals compared to percentages.

![](https://github.com/PDBoegel/HeartMortality/raw/master/histoAfram.png)

<div style="text-indent: 30px;">Several groups of explanatory variables presented serious collinearity concerns.  The data on the
percent of population who is male and the percent of population who is female resulted in a perfect
correlation (r = -1.00). To eliminate such a high level of collinearity, the report will only work
with the percentage of the population who is male, effectively eliminating unnecessary data and
making the linear models simpler. The second instance of serious collinearity (r = -1.00) existed
between the percent of the population who is under 30 years of age, between 30 and 65 years of age,
and over 65 years of age. To resolve this issue, an entirely new variable was created by combining two of the data sets to produce the percent of the population who is under 65 years of age. By
reducing the variable count from three to one, the respective linear models became less complicated,
and allow for better testing on whether this variable is significant in explaining an individual’s
chance of heart disease mortality.

<div style="text-indent: 30px;">To find unusual points in the data, scripts were written to find high leverage points and outliers.
A leverage plot was created to visually represent leverage values for all observations.
Once we found the average leverage value, 96 observations
were identified that exceeded the threshold to be considered a “high leverage point” (3 * average
leverage value). After deleting those high leverage points from the model, the R^2 value dropped from
0.5372 to 0.5185 - a 3.5% decrease.

![](https://github.com/PDBoegel/HeartMortality/raw/master/histoLev.png)

<div style="text-indent: 30px;">Similar steps were followed to detect outliers in the data. First, a standardized residual plot was
created to visually represent all of the standardized residuals in the model. Then script was written
which detected 153 observations that have an absolute value of greater than 2 for its standardized
residual. Through an examination of the observations between the outliers and high leverage points,
it is noteworthy that no points in the model were both outliers and high leverage points (Appendix H).
When the outliers were removed from the regression (keeping the high leverage points), the R^2 value
increased from 0.5372 to 0.5917 - a 10.5% increase. A regression without both high leverage points
and outliers resulted in an R^2 value of 0.5951 - a 10.8% increase from the original regression.

<div style="text-indent: 30px;">Through this sensitivity analysis, this report concluded that the model is relatively insensitive
to the high leverage points. The outliers, however, in the data significantly reduce the R^2 value.
The removal of high leverage points and outliers had no effect on the significance of individual
explanatory variables because each variable was significant at a 1% significance level in each
regression.
	
#Empirical Analysis

<div style="text-indent: 30px;">The data was compiled into three preliminary models: a model with categorical data (the Category
Model), a model using logarithmic totals of the explanatory variables (the Log Totals Model), and a
model using percent variables (the PCT Model). The Category Model resulted in a model that was very
general, it greatly lowered the resulting reduced-R^2, and it was very complex. With these three
reasons, the Category Model was deemed insufficient and was thereby rejected. The Log Totals Model
and the PCT Model admittedly have similarities. Both models, for example, attempt to model the
percentage increase of their  respective variables in comparison to the percentage increase in Heart
Disease mortality. Where they differ is in the reality that the Log Totals Model looks to the totals
(percentage of variable * population size) then logarithmically scales the variable to produce the
percentage change. The PCT Model, in contrast, immediately uses the percentage of the variable and
takes the natural logarithm of it, allowing scrutinization of the percentage increase in the
percentage variable. This report ultimately deemed the PCT Model as its champion because the
Variation Inflation Factors in the Log Total Model were outrageously high. To further validate the
PCT Model, this report first used all variables in the initial run of linear models. Then, using an
F-Test on only the statistically significant, the desired reduced model was created.

![](https://github.com/PDBoegel/HeartMortality/raw/master/bCoef.png)


<div style="text-indent: 30px;">From the reduced model, the PCT Model, this report will comment on the data’s anomalies and
formulate its findings. Contrarily to what would be expected, the PCTMALE beta is negative, implying
that as the male population of a county increases, Heart Disease mortality would be predicted to
decrease according to the PCT Model; this is not intuitively expected because men have a higher
likelihood of contracting Heart Disease. Similarly, the beta coefficient for PCTPOPUNDER65 is
positive, which implies that adding more young people significantly raises the likelihood of Heart
Disease mortality. This could be a result of the age limit being too inclusive to the range of ages
that are likely to contract Heart Disease (Adults aged 50 - 65). This report kept both variables in
the model because gender and age were deemed a significant demographic; future studies could further
test these seemingly counter-intuitive relationships. After the PCTMALE and PCTPOPUNDER65 anomalies,
it is moreover notable that the HIGHEDUCATION beta does not seem to have a significant effect on
HDMORTRATE, but interestingly both LOWEDUCATION and MEDEDUCATION do seem to have significant effect.
Perhaps this effect is a result of the higher amounts of people in LOWEDUCATION and MEDEDUCATION. The
reduced model additionally filtered out several variables thought to be significant. These were
PCTUNEMPLOYED, HIGHEDUCATION, and  PCTNATIVEAM, which were initially predicted to be more important
than the model results suggest. Next, another instance of collinearity arose post data analysis and
during the model development. This collinearity exists between LNPOPDENSITY and LNHOUSINGUNITDENSITY.
The report regards the reason behind this high collinearity to be the fact that the need for housing
increases as a population size swells. Surprisingly though, high collinearity did not show in the
model between PCTOBESE and PCTDIABETES; this could possibly result from the fact that Type I Diabetes
is hereditary and not caused by obesity. In sum, the largest impact on the PCT Model was the variable
log(PCTPOPUNDER65) with coefficient 1.18317862. This means for every 1% increase in PCTPOPUNDER65,
the HDMORTPERPERSON is expected to increase by 1.1939%. Perhaps it was so impactful because the
population under 65 includes such a vast proportion of the general population. The second largest
impact was PCTDIABETES with coefficient 0.33450356. The smallest impact belonged to the PCTASIANAM
with coefficient -0.02203009, likely since the population of Asian Americans is relatively small
compared to other proportions of the general population. 
 
#Concluding Remarks
  
<div style="text-indent: 30px;">Throughout the direction of this report, the aim has been to provide sound significant evidence (or
lack of evidence) to the impact socioeconomic factors of counties of the United States have on Heart
Disease mortality. To do this, data was gathered primarily from government regulated sources, such as
the U.S. Census, and then fitted into linear models. The linear models revealed that how important
age and general health is to the probability of contracting Heart Disease. This report acknowledges
it has limitations in the data quality and modeling. With the data quality for example, the
population data is an estimate of the 2013 population based on the past historical census data of
2010. This government gathered information, however, is the best available data regarding the United
States population. For example of modeling strategy, the initial linear model of all the explanatory
variables had an R^2 value equal to 0.5005. It was only after significant data manipulation that the
data began to form together and become neatly coalesced and analyzable. In future reports, the data
could be better aligned by year to prevent any potential mal-arrangement of values, as well as could
consider containing further divisions of age groups. Testing the impact of socioeconomic factors by
area on Heart Disease need not be limited to the United States, but rather could be extended to other
countries individually and to the globe altogether. By combining its effects in a global stage, one
could show how socioeconomic factors by area impacts humanity as a whole.

#Appendix

##A

###R Code

```{r}
heartmortCOMPLETE = read.csv(file = "https://raw.githubusercontent.com/PDBoegel/HeartMortality/master/HeartMort.csv", header = TRUE)
heartmort = heartmortCOMPLETE[-c(1:4,7,24:26)] #Getting rid of variables for metadata and other dependent variable
options(max.print = 4000)
```

###Basic data manipulation to better fit normality assumptions for linear models

```{r}
heartmort$PCTPOPUNDER65 = heartmortCOMPLETE$PCTPOP30TO65 + heartmortCOMPLETE$PCTPOPUNDER30 # To account for elderly population
heartmort <- subset(heartmort, AVGINCOMEPERPERSON > 0 & PCTASIANAM != 0 & PCTAFRAM != 0 & PCTNATIVEAM != 0) # 26 counties had 0 avgincome/PCTAFRAM/PCTNATIVEAM/PCTASAINAM, removal should not affect study and makes histogram/log transform variables easier to make/use later
summaryOfVars <- summary(heartmort)
# Look at appendix B for summaryOfVars
```
```{r, echo=FALSE}
heartmort <- heartmort[,c(1:6,14:16,19,7:13,18,20)] #Organization to make category variables easier later on. Does not need to go into document
heartmort[,c(7:19)] <- heartmort[,c(7:19)]/100 # Making percents into numbers [0,1]
```
```{r}
# We log totals imeediately as popsize varies widely from county to county
totCols <- c("LNTOTLOWEDU","LNTOTMEDEDU","LNTOTHIGHEDU","LNTOTOBESE","LNTOTDIABETES","LNTOTMALE","LNTOTFEMALE","LNTOTWHITE","LNTOTAFRAM","LNTOTASIANAM","LNTOTNATIVEAM","LNTOTUNEMPLOYED","LNTOTNONELDERLY")
heartmort[totCols] <- log(heartmort$POPSIZE * heartmort[7:19])

# Making categories for PCT variables
catCols <- c("CATHDMORTPERPERSON","CATLOWEDU","CATMEDEDU","CATHIGHEDU","CATOBESE","CATDIABETES","CATMALE","CATFEMALE","CATWHITE","CATAFRAM","CATASIANAM","CATNATIVEAM","CATUNEMPLOYED","CATNONELDERLY")
heartmort[catCols] <- 0
df <- lapply(c(2,7:19), function(i) cut(heartmort[,i], c(-.01, max(0, as.numeric(quantile(heartmort[,i], probs = 0.25)) - (1.5 * (as.numeric(quantile(heartmort[,i], probs = 0.75)) - as.numeric(quantile(heartmort[,i],probs = 0.25))))), min(1, as.numeric(quantile(heartmort[,i], probs = 0.75)) + (1.5 * as.numeric((quantile(heartmort[,i], probs = 0.75)) - as.numeric(quantile(heartmort[,i], probs = 0.25))))),1.01), right = FALSE, labels = c(0:2)))

heartmort[33:46] <- df
colnames(heartmort)[33:46] <- catCols
# Log transformations from what was specified above
logCols <- c("LNPOPSIZE","LNHDMORTPERPERSON","LNPOPDENSITY","LNHOUSINGUNITS","LNHOUSINGUNITSDENSITY","LNAVGINCOMEPERPERSON")
heartmort[logCols] <- log(heartmort[1:6])
```

###linear model analysis 

####Three beggining full candidate models

```{r}
attach(heartmort)
totlm = lm(LNHDMORTPERPERSON ~ LNTOTLOWEDU + LNTOTMEDEDU + LNTOTHIGHEDU + LNTOTAFRAM + LNTOTASIANAM + LNTOTDIABETES + LNTOTMALE + LNTOTNATIVEAM + LNTOTNONELDERLY + LNTOTOBESE + LNTOTUNEMPLOYED + LNTOTWHITE + LNPOPDENSITY + LNHOUSINGUNITSDENSITY + LNAVGINCOMEPERPERSON, data = heartmort)
# Look at Appendix C for summary(totlm)
```

```{r}
pctlm <- lm(LNHDMORTPERPERSON ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(HIGHEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTMALE) + log(PCTNATIVEAM) + log(PCTPOPUNDER65) + log(PCTOBESE) + log(PCTUNEMPLOYED) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY + LNAVGINCOMEPERPERSON, data = heartmort)
# Look at Appendix C for summary(pctlm)
```

```{r}
catlm = lm(LNHDMORTPERPERSON ~ factor(CATLOWEDU) + factor(CATMEDEDU) + factor(CATHIGHEDU) + LNTOTDIABETES + factor(CATMALE) + LNTOTNONELDERLY + LNTOTOBESE + LNTOTUNEMPLOYED + factor(CATWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY + LNAVGINCOMEPERPERSON, data = heartmort)
# Look at Appendix C for summary(catlm)
```

####Reduced model

```{r}
model <- lm(LNHDMORTPERPERSON ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTMALE) + log(PCTPOPUNDER65) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmort)
# Look at Appendix C for summary(model)
# Look at Appendix C for anova(model, pctlm) 
```

###Sensitivity Analysis 

####Model without high leverage points

```{r}
leverage = hatvalues(model) 

k = length(model$coefficients)-1
n = dim(heartmort)[1]
averagelev = (k+1)/n
levs <-as.numeric(which(leverage > 3*averagelev))
heartmortNoLev = heartmort[-levs,]
modelNoLev <- lm(LNHDMORTPERPERSON ~ LNTOTHIGHEDU + LNTOTAFRAM + LNTOTASIANAM + LNTOTDIABETES + LNTOTMALE + LNTOTNATIVEAM + LNTOTNONELDERLY + LNTOTOBESE + LNTOTWHITE + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmortNoLev)
# Look at Appendix C for summary(modelNoLev)
```

####Model without high standardized residuals

```{r}
resid = as.numeric(which(abs(rstandard(model)) > 2))
heartmortNoHighResid = heartmort[-resid,]
modelNoHighResid <- lm(LNHDMORTPERPERSON ~ LNTOTHIGHEDU + LNTOTAFRAM + LNTOTASIANAM + LNTOTDIABETES + LNTOTMALE + LNTOTNATIVEAM + LNTOTNONELDERLY + LNTOTOBESE + LNTOTWHITE + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmortNoHighResid)
# Look at Appendix C for summary(modelNoHighResid)
```

####Model without both high std residuals and leverage points

```{r}
heartmortFinal = heartmort[c(-resid,-levs),]
modelFinal <- lm(LNHDMORTPERPERSON ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTMALE) + log(PCTPOPUNDER65) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmortFinal)
# Look at Appendix C for summary(modelFinal)
```

###Collinearity

####Table of Correlations
```{r, message=FALSE, warning=FALSE}
#Tables split up into correlations we were worried about being collinear

#Table of correlations : EDUCATION LEVEL AND OBESITY/DIABETES RATES
cor(heartmort[7:11])

#Table of correlations : DEMOGRAPHIC
cor(heartmort[12:17])

#Table of correlations : POPULATION, HOUSING, INCOME
cor(heartmort[c(1,3:6)])
```

####Variance Inflation Factors

```{r, warning=FALSE, message=FALSE}
library(faraway)
vif(modelFinal)
```

##B 

###1. Summary statistics and histograms of original variables
```{r}
summaryOfVars
```
```{r, results='hide'}

par(mfrow = c(2,3))
lapply(1:19, function(i) boxplot(heartmort[,i], xlab = names(heartmort)[i], main = paste("boxplot of", names(heartmort)[i])))
```
```{r, echo=FALSE}
par(mfrow = c(2,3))
```
```{r, results='hide'}
par(mfrow = c(2,3))
lapply(1:19, function(i) hist(heartmort[,i], xlab = names(heartmort)[i], main = paste("Histogram of", names(heartmort)[i])))
```

###2. Summary statistics and histograms of transformed variables

```{r, results='hide'}
par(mfrow = c(2,3))
lapply(c(20:32,47:52), function(i) hist(heartmort[,i], xlab = names(heartmort)[i], main = paste("Histogram of", names(heartmort)[i]))) 
```

##C

###1. Linear model using Log Totals

```{r}
summary(totlm)
```

###2. Linear model using Categorical

```{r}
summary(catlm)
```

###3. Linear model using log percentages

```{r}
summary(pctlm)
```

###4. Reduced linear model with log percents

```{r}
summary(model)
anova(model, pctlm)
```

###5. Reduced linear model with log percents without high leverage points

```{r}
hist(leverage, main="Histogram of Leverages", xlab = "Leverage", breaks = 15)
summary(modelNoLev)
```

###6. Reduced linear model with log percents without outliers
```{r}
hist(rstandard(model), main="Histogram of Standardized Residuals", xlab = "Standardized Residual")
summary(modelNoHighResid)
```

###7. Final model with log percents that do no contain outliers or high leverage points
```{r}
summary(modelFinal)
```

##D

###1. Added Variable Plot for PCTMALE

```{r}
e1 = lm(LNHDMORTPERPERSON ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTPOPUNDER65) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmort)
e2 = model <- lm(log(PCTMALE) ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTPOPUNDER65) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmort)

e1resid = residuals(e1)
e2resid = residuals(e2)

plot(e1resid,e2resid,main = "Added Variable Plot")

abline(lm(e1resid ~ e2resid), col="red")
```

###2. Added Variable Plot for PCTPOPUNDER65

```{r}
e3 = lm(LNHDMORTPERPERSON ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTMALE) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmortFinal)
e4 = model <- lm(log(PCTPOPUNDER65) ~ log(LOWEDUCATION) + log(MEDEDUCATION) + log(PCTAFRAM) + log(PCTASIANAM) + log(PCTDIABETES) + log(PCTMALE) + log(PCTOBESE) + log(PCTWHITE) + LNPOPDENSITY + LNHOUSINGUNITSDENSITY, data = heartmortFinal)

e3resid = residuals(e3)
e4resid = residuals(e4)

plot(e3resid,e4resid,main = "Added Variable Plot")

abline(lm(e4resid ~ e3resid), col="red")
```

##E

**Coefficents and t-statistics for the final model**

```{r}
coefficients = c(modelFinal$coefficients)
tvalues = c(-49.987 , 16.058 , 11.631 , 9.069 , -4.988 , 15.298 , -3.545 , 13.433 , 3.413 , 5.284 , -8.316 , 8.192)

betaframe = data.frame(coefficients , tvalues)
betaframe
```

##H

```{r, warning=FALSE, message=FALSE}
# **Proving there are no observations that are high leverage points AND outliers**
sum((which(abs(rstandard(model)) > 2) == which(leverage > 3*averagelev)))
```